
import os
import argparse
import torch
import numpy as np
from ase.db import connect
import schnetpack as spk

def evaluate_model_loss(model_path, db_path, split_path):
    
    def calculate_loss(model, db_path, indices):
        loss = 0
        for idx in indices:
            with connect(db_path) as conn:
                target = conn.get(int(idx) + 1).data['fock_matrix']
                atoms = conn.get_atoms(int(idx)+1)
            converter = spk.interfaces.AtomsConverter(neighbor_list=spk.transform.ASENeighborList(cutoff=5.0), dtype=torch.float32, device=device)
            input = converter(atoms)
            pred = model(input)['fock_matrix'].detach().cpu().numpy()
            loss += np.sum((pred - target.flatten())**2)
            loss /= len(train_idx) * pred.shape[0]
        return loss
        
    if torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')
    model = torch.load(model_path, map_location=device).to(device)
    
    split = np.load(split_path)
    train_idx, val_idx, test_idx = split['train_idx'], split['val_idx'], split['test_idx']
    
    model.train()
    train_loss = calculate_loss(model, db_path, train_idx)

    model.eval()
    val_loss = calculate_loss(model, db_path, val_idx)
    test_loss = calculate_loss(model, db_path, test_idx)

    return train_loss, val_loss, test_loss
